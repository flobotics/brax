{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssCOanHc8JH_"
   },
   "source": [
    "# Training in Brax\n",
    "\n",
    "In [Brax Basics](https://colab.research.google.com/github/google/brax/blob/main/notebooks/basics.ipynb) we learned about the core components of Brax: static system definitions, dynamic state, and dynamic input.  With these core components, we can optimize a function of the Brax simulation to learn all kinds of fun and useful behaviors in a physical environment.\n",
    "\n",
    "Brax provides a [gym](https://gym.openai.com/)-like environment for training policies.  Brax comes with PPO, SAC, evolutionary search, and trajectory optimization algorithms out of the box.  Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_sOmCoOrF0F8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-09 15:58:19.787877: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/opt/ros/galactic/opt/yaml_cpp_vendor/lib:/opt/ros/galactic/opt/rviz_ogre_vendor/lib:/opt/ros/galactic/lib/x86_64-linux-gnu:/opt/ros/galactic/lib\n"
     ]
    }
   ],
   "source": [
    "#@title Colab setup and imports\n",
    "#@markdown ## ⚠️ PLEASE NOTE:\n",
    "#@markdown This colab runs best using a TPU runtime.  From the Colab menu, choose Runtime > Change Runtime Type, then select **'TPU'** in the dropdown.\n",
    "\n",
    "from datetime import datetime\n",
    "import functools\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, clear_output\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "    try:\n",
    "      import brax\n",
    "    except ImportError:\n",
    "      !pip install git+https://github.com/flobotics/brax.git@custom_envs\n",
    "      clear_output()\n",
    "      import brax\n",
    "else:\n",
    "    import brax\n",
    "\n",
    "from brax import envs\n",
    "from brax.training import ppo, sac\n",
    "from brax.io import html\n",
    "\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "  from jax.tools import colab_tpu\n",
    "  colab_tpu.setup_tpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tm8zbPBcJ5RJ"
   },
   "source": [
    "In [Brax Basics](https://colab.research.google.com/github/google/brax/blob/main/notebooks/basics.ipynb) we explored simple systems with a couple of bodies and two joints.  Most practical systems have many more bodies, joints, and actuators.  Larger systems are tedious to author by hand, so Brax comes with a few built-in systems that are useful for quick experiments:\n",
    "\n",
    "**[ant](https://github.com/google/brax/blob/main/brax/envs/ant.py)** from [OpenAI Gym Ant-v2](https://gym.openai.com/envs/Ant-v2/): make a four-legged creature walk forward as fast as possible\n",
    "\n",
    "**[humanoid](https://github.com/google/brax/blob/main/brax/envs/humanoid.py)** from [OpenAI Gym Humanoid-v2](https://gym.openai.com/envs/Humanoid-v2/): make a three-dimensional bipedal robot walk forward as fast as possible, without falling over.\n",
    "\n",
    "**[halfcheetah](https://github.com/google/brax/blob/main/brax/envs/halfcheetah.py)** from [OpenAI Gym HalfCheetah-v2](https://gym.openai.com/envs/HalfCheetah-v2/): make a two-dimensional two-legged creature walk forward as fast as possible\n",
    "\n",
    "**[fetch](https://github.com/google/brax/blob/main/brax/envs/fetch.py)**: make a three-dimensional dog chase after a moving target.\n",
    "\n",
    "**[grasp](https://github.com/google/brax/blob/main/brax/envs/grasp.py)**: a grabber hand must pick up a ball and carry it to a moving target.\n",
    "\n",
    "**[ur5e](https://github.com/google/brax/blob/main/brax/envs/ur5e.py)**: a ur5e robot arm that moves its end effector to a series of targets.\n",
    "\n",
    "**[reacher](https://github.com/google/brax/blob/main/brax/envs/reacher.py)**: from [OpenAI Gym Reacher-v2](https://gym.openai.com/envs/Reacher-v2/): makes a two-joint reacher arm move its tip to a target.\n",
    "\n",
    "As systems get more complex, it becomes useful to have some way of visualizing them in 3D, to ensure you've defined your system the way you think you have.  Brax includes a little 3D viewer that makes it easy to quickly debug systems and trajectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "NaJDZqhCLovU",
    "outputId": "b8f9e4fc-9b2b-4e6f-891a-4fbdafc0a194"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "\n",
       "  <head>\n",
       "    <title>brax visualizer</title>\n",
       "    <style>\n",
       "      body {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "      }\n",
       "\n",
       "      #brax-viewer {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        height: 480px;\n",
       "      }\n",
       "    </style>\n",
       "  </head>\n",
       "\n",
       "  <body>\n",
       "    <script type=\"application/javascript\">\n",
       "    var system = {\"config\": {\"bodies\": [{\"name\": \"$ BallBody\", \"colliders\": [{\"sphere\": {\"radius\": 1.0}}], \"inertia\": {\"x\": 1.0, \"y\": 1.0, \"z\": 1.0}, \"mass\": 10.0, \"frozen\": {\"position\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"rotation\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"all\": false}}, {\"name\": \"Aux 1\", \"colliders\": [{\"sphere\": {\"radius\": 1.0}}], \"inertia\": {\"x\": 1.0, \"y\": 1.0, \"z\": 1.0}, \"mass\": 1.001, \"frozen\": {\"position\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"rotation\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"all\": false}}, {\"name\": \"Ground\", \"colliders\": [{\"plane\": {}}], \"inertia\": {\"x\": 1.0, \"y\": 1.0, \"z\": 1.0}, \"mass\": 1.0, \"frozen\": {\"position\": {\"x\": 1.0, \"y\": 1.0, \"z\": 1.0}, \"rotation\": {\"x\": 1.0, \"y\": 1.0, \"z\": 1.0}, \"all\": true}}], \"joints\": [{\"name\": \"$ BallBody_Aux 1\", \"stiffness\": 15000.0, \"parent\": \"$ BallBody\", \"child\": \"Aux 1\", \"parentOffset\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"childOffset\": {\"y\": 2.2, \"x\": 0.0, \"z\": 0.0}, \"rotation\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"angularDamping\": 35.0, \"angleLimit\": [{\"min\": -10.0, \"max\": 10.0}]}], \"actuators\": [{\"name\": \"$ BallBody_Aux 1\", \"joint\": \"$ BallBody_Aux 1\", \"strength\": 300.0, \"torque\": {}}], \"friction\": 0.6, \"gravity\": {\"z\": -9.8, \"x\": 0.0, \"y\": 0.0}, \"angularDamping\": -0.05, \"baumgarteErp\": 0.1, \"collideInclude\": [{\"first\": \"$ BallBody\", \"second\": \"Ground\"}], \"dt\": 0.0167, \"substeps\": 30, \"frozen\": {\"all\": false}, \"elasticity\": 0.0, \"velocityDamping\": 0.0, \"defaults\": []}, \"pos\": [[[0.0, 0.0, 1.0], [0.0, -2.200000047683716, 1.0], [-0.0, -0.0, -0.0]]], \"rot\": [[[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]]};\n",
       "    </script>\n",
       "\n",
       "    <div id=\"brax-viewer\"></div>\n",
       "\n",
       "    <script type=\"module\">\n",
       "      import {Viewer} from 'https://cdn.jsdelivr.net/gh/google/brax@6039109a102ca2ed4baaaf5bc595bdf3aaecc89f/js/viewer.js';\n",
       "      const domElement = document.getElementById('brax-viewer');\n",
       "      var viewer = new Viewer(domElement, system);\n",
       "    </script>\n",
       "  </body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Visualizing pre-included Brax environments { run: \"auto\" }\n",
    "\n",
    "env_name = \"balltest\"  # @param ['balltest','simtoreal_three_servo_arm_ax12a','crawler5','testenv','testenv2','ant', 'humanoid', 'fetch', 'grasp', 'halfcheetah', 'ur5e', 'reacher']\n",
    "env_fn = envs.create_fn(env_name=env_name)\n",
    "env = env_fn()\n",
    "jit_env_reset = jax.jit(env.reset)\n",
    "state = jit_env_reset(rng=jax.random.PRNGKey(seed=0))\n",
    "\n",
    "def visualize(sys, qps):\n",
    "  \"\"\"Renders a 3D visualization of the environment.\"\"\"\n",
    "  return HTML(html.render(sys, qps))\n",
    "\n",
    "visualize(env.sys, [state.qp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25iky4mITUhh"
   },
   "source": [
    "# Training\n",
    "\n",
    "Brax provides out of the box the following training algorithms:\n",
    "\n",
    "* [Proximal policy optimization](https://github.com/google/brax/blob/main/brax/training/ppo.py)\n",
    "* [Soft actor-critic](https://github.com/google/brax/blob/main/brax/training/sac.py)\n",
    "* [Evolutionary strategy](https://github.com/google/brax/blob/main/brax/training/es.py)\n",
    "* [Analytic policy gradients](https://github.com/google/brax/blob/main/brax/training/apg.py)\n",
    "\n",
    "Trainers take as input an environment function and some hyperparameters, and return an inference function to operate the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "4vgMSWODfyMC",
    "outputId": "e9de2895-6744-425d-9940-9a650810dbff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to jit: 0:00:37.945510\n",
      "time to train: 0:00:07.982862\n"
     ]
    }
   ],
   "source": [
    "#@title Training some pre-included Brax environments\n",
    "\n",
    "# We determined some reasonable hyperparameters offline and share them here.\n",
    "train_fn = {\n",
    "  'ant': functools.partial(\n",
    "      ppo.train, num_timesteps = 50000000, log_frequency = 20,\n",
    "      reward_scaling = 10, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 1, unroll_length = 5, num_minibatches = 32,\n",
    "      num_update_epochs = 4, discounting = 0.95, learning_rate = 3e-4,\n",
    "      entropy_cost = 1e-2, num_envs = 2048, batch_size = 1024\n",
    "  ),\n",
    "  'humanoid': functools.partial(\n",
    "      sac.train, num_timesteps = 1048576 * 5,\n",
    "      log_frequency = 131012, reward_scaling = 30, episode_length = 1000,\n",
    "      normalize_observations = True, action_repeat = 1, discounting = 0.99,\n",
    "      learning_rate = 6e-4, num_envs = 64, batch_size = 512,\n",
    "      min_replay_size = 8192, max_replay_size = 1048576,\n",
    "      grad_updates_per_step = 0.125, max_devices_per_host=4\n",
    "  ),\n",
    "  'fetch': functools.partial(\n",
    "      ppo.train, num_timesteps = 100_000_000, log_frequency = 20,\n",
    "      reward_scaling = 5, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 1, unroll_length = 20, num_minibatches = 32,\n",
    "      num_update_epochs = 4, discounting = 0.997, learning_rate = 3e-4,\n",
    "      entropy_cost = 0.001, num_envs = 2048, batch_size = 256\n",
    "  ),\n",
    "  'grasp': functools.partial(\n",
    "      ppo.train, num_timesteps = 600_000_000, log_frequency = 10,\n",
    "      reward_scaling = 10, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 1, unroll_length = 20, num_minibatches = 32,\n",
    "      num_update_epochs = 2, discounting = 0.99, learning_rate = 3e-4,\n",
    "      entropy_cost = 0.001, num_envs = 2048, batch_size = 256\n",
    "  ),\n",
    "  'halfcheetah': functools.partial(\n",
    "      ppo.train, num_timesteps = 100_000_000, log_frequency = 10,\n",
    "      reward_scaling = 1, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 1, unroll_length = 20, num_minibatches = 32,\n",
    "      num_update_epochs = 8, discounting = 0.95, learning_rate = 3e-4,\n",
    "      entropy_cost = 0.001, num_envs = 2048, batch_size = 512\n",
    "  ),\n",
    "  'ur5e': functools.partial(\n",
    "      ppo.train, num_timesteps = 20_000_000, log_frequency = 20,\n",
    "      reward_scaling = 10, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 1, unroll_length = 5, num_minibatches = 32,\n",
    "      num_update_epochs = 4, discounting = 0.95, learning_rate = 2e-4,\n",
    "      entropy_cost = 1e-2, num_envs = 2048, batch_size = 1024,\n",
    "      max_devices_per_host = 8\n",
    "  ),\n",
    "  'reacher': functools.partial(\n",
    "      ppo.train, num_timesteps = 100_000_000, log_frequency = 20,\n",
    "      reward_scaling = 5, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 4, unroll_length = 50, num_minibatches = 32,\n",
    "      num_update_epochs = 8, discounting = 0.95, learning_rate = 3e-4,\n",
    "      entropy_cost = 1e-3, num_envs = 2048, batch_size = 256,\n",
    "      max_devices_per_host = 8, seed = 1),\n",
    "  'testenv': functools.partial(\n",
    "      ppo.train, num_timesteps = 100_000_000, log_frequency = 20,\n",
    "      reward_scaling = 5, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 1, unroll_length = 20, num_minibatches = 32,\n",
    "      num_update_epochs = 4, discounting = 0.997, learning_rate = 3e-4,\n",
    "      entropy_cost = 0.001, num_envs = 2048, batch_size = 256\n",
    "  ),\n",
    "  'testenv2': functools.partial(\n",
    "      ppo.train, num_timesteps = 100_000_000, log_frequency = 20,\n",
    "      reward_scaling = 5, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 1, unroll_length = 20, num_minibatches = 32,\n",
    "      num_update_epochs = 4, discounting = 0.997, learning_rate = 3e-4,\n",
    "      entropy_cost = 0.001, num_envs = 2048, batch_size = 256\n",
    "  ),\n",
    "  'crawler5': functools.partial(\n",
    "      ppo.train, num_timesteps = 100_000_000, log_frequency = 20,\n",
    "      reward_scaling = 5, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 4, unroll_length = 50, num_minibatches = 32,\n",
    "      num_update_epochs = 8, discounting = 0.95, learning_rate = 3e-4,\n",
    "      entropy_cost = 1e-3, num_envs = 2048, batch_size = 256,\n",
    "      max_devices_per_host = 8, seed = 1),\n",
    "  'simtoreal_three_servo_arm_ax12a': functools.partial(\n",
    "      ppo.train, num_timesteps = 100_000_000, log_frequency = 20,\n",
    "      reward_scaling = 5, episode_length = 1000, normalize_observations = True,\n",
    "      action_repeat = 4, unroll_length = 50, num_minibatches = 32,\n",
    "      num_update_epochs = 8, discounting = 0.95, learning_rate = 3e-4,\n",
    "      entropy_cost = 1e-3, num_envs = 2048, batch_size = 256,\n",
    "      max_devices_per_host = 8, seed = 1),\n",
    "  'balltest': functools.partial(\n",
    "      ppo.train, num_timesteps = 100, log_frequency = 20,\n",
    "      reward_scaling = 5, episode_length = 10, normalize_observations = True,\n",
    "      action_repeat = 4, unroll_length = 50, num_minibatches = 32,\n",
    "      num_update_epochs = 8, discounting = 0.95, learning_rate = 3e-4,\n",
    "      entropy_cost = 1e-3, num_envs = 2048, batch_size = 256,\n",
    "      max_devices_per_host = 8, seed = 1),\n",
    "}[env_name]\n",
    "max_y = {'ant': 6000, \n",
    "         'humanoid': 12000, \n",
    "         'fetch': 15, \n",
    "         'grasp': 100, \n",
    "         'halfcheetah': 8000,\n",
    "         'ur5e': 10,\n",
    "         'reacher': 5,\n",
    "         'testenv': 15000,\n",
    "         'testenv2': 15000,\n",
    "         'crawler5': 15000,\n",
    "         'simtoreal_three_servo_arm_ax12a': 15000,\n",
    "         'balltest': 5,}[env_name]\n",
    "\n",
    "min_y = {'reacher': -100}.get(env_name, 0)\n",
    "min_y = {'testenv': -10000}.get(env_name, 0)\n",
    "min_y = {'testenv2': -10000}.get(env_name, 0)\n",
    "min_y = {'crawler5': -10000}.get(env_name, 0)\n",
    "min_y = {'simtoreal_three_servo_arm_ax12a': -10000}.get(env_name, 0)\n",
    "min_y = {'balltest': -100}.get(env_name, 0)\n",
    "\n",
    "xdata = []\n",
    "ydata = []\n",
    "times = [datetime.now()]\n",
    "\n",
    "def progress(num_steps, metrics):\n",
    "  times.append(datetime.now())\n",
    "  xdata.append(num_steps)\n",
    "  ydata.append(metrics['eval/episode_reward'])\n",
    "  clear_output(wait=True)\n",
    "  plt.xlim([0, train_fn.keywords['num_timesteps']])\n",
    "  plt.ylim([min_y, max_y])\n",
    "  plt.xlabel('# environment steps')\n",
    "  plt.ylabel('reward per episode')\n",
    "  plt.plot(xdata, ydata)\n",
    "  plt.show()\n",
    "\n",
    "inference_fn, params, _ = train_fn(environment_fn=env_fn, progress_fn=progress)\n",
    "\n",
    "print(f'time to jit: {times[1] - times[0]}')\n",
    "print(f'time to train: {times[-1] - times[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGPyeF8Jsj_M"
   },
   "source": [
    "The trainers return an inference function and the final set of metrics gathered during evaluation.  Here, we take the inference function and visualize one episode's trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "RNMLEyaTspEM",
    "outputId": "02706026-c31a-4483-e5ff-450790f2370a"
   },
   "outputs": [],
   "source": [
    "#@title Visualizing a trajectory of the learned inference function\n",
    "\n",
    "jit_env_step = jax.jit(env.step)\n",
    "jit_inference_fn = jax.jit(inference_fn)\n",
    "rng = jax.random.PRNGKey(seed=0)\n",
    "reset_key, rng = jax.random.split(rng)\n",
    "state = jit_env_reset(rng=reset_key)\n",
    "qps = []\n",
    "while not state.done:\n",
    "  qps.append(state.qp)\n",
    "  tmp_key, rng = jax.random.split(rng)\n",
    "  act = jit_inference_fn(params, state.obs, tmp_key)\n",
    "  state = jit_env_step(state, act)\n",
    "\n",
    "visualize(env.sys, qps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Brax Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
